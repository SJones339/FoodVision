{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f59015",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2213aa7a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /content/drive/MyDrive/\n",
    "mkdir -p vp-project-branch\n",
    "cd vp-project-branch\n",
    "git clone https://github.com/SJones339/FoodVision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33efd08",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics\n",
    "!pip install datasets\n",
    "!pip install roboflow\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from roboflow import Roboflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a2c49a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "TARGET_DIR = \"/content/drive/MyDrive/vp-project-branch/FoodVision/data/foodseg_pp\"\n",
    "\n",
    "train_img_dir = f\"{TARGET_DIR}/images/train\"\n",
    "train_lbl_dir = f\"{TARGET_DIR}/labels/train\"\n",
    "val_img_dir   = f\"{TARGET_DIR}/images/val\"\n",
    "val_lbl_dir   = f\"{TARGET_DIR}/labels/val\"\n",
    "\n",
    "os.makedirs(train_img_dir, exist_ok=True)\n",
    "os.makedirs(train_lbl_dir, exist_ok=True)\n",
    "os.makedirs(val_img_dir, exist_ok=True)\n",
    "os.makedirs(val_lbl_dir, exist_ok=True)\n",
    "\n",
    "# Load dataset \n",
    "ds = load_dataset(\"EduardoPacheco/FoodSeg103\", trust_remote_code=True)\n",
    "\n",
    "train_ds = ds[\"train\"]\n",
    "val_ds   = ds[\"validation\"]  # dataset already has validation split\n",
    "\n",
    "#Label -> YOLO polygons \n",
    "def convert_split(split, img_dir, lbl_dir):\n",
    "    print(\"Detected mask key: label\")\n",
    "\n",
    "    for i, item in enumerate(tqdm(split)):\n",
    "        img = np.array(item[\"image\"])\n",
    "        mask = np.array(item[\"label\"])   # <-- Correct mask key\n",
    "        H, W = mask.shape\n",
    "\n",
    "        img_path = f\"{img_dir}/{i}.jpg\"\n",
    "        cv2.imwrite(img_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "        label_path = f\"{lbl_dir}/{i}.txt\"\n",
    "        with open(label_path, \"w\") as f:\n",
    "\n",
    "            # classes present on image\n",
    "            classes = np.unique(mask)\n",
    "            classes = classes[classes != 0]   # remove background class 0\n",
    "\n",
    "            for cls in classes:\n",
    "                binmask = (mask == cls).astype(np.uint8)\n",
    "\n",
    "                contours, _ = cv2.findContours(\n",
    "                    binmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "                )\n",
    "\n",
    "                for cnt in contours:\n",
    "                    if len(cnt) < 3:\n",
    "                        continue\n",
    "\n",
    "                    poly = cnt.reshape(-1, 2).astype(float)\n",
    "                    poly[:, 0] /= W\n",
    "                    poly[:, 1] /= H\n",
    "\n",
    "                    poly = poly.flatten().tolist()\n",
    "\n",
    "                    line = f\"{cls} \" + \" \".join([f\"{p:.6f}\" for p in poly]) + \"\\n\"\n",
    "                    f.write(line)\n",
    "\n",
    "#convert both splits \n",
    "print(\"Converting training...\")\n",
    "convert_split(train_ds, train_img_dir, train_lbl_dir)\n",
    "\n",
    "print(\"Converting validation...\")\n",
    "convert_split(val_ds, val_img_dir, val_lbl_dir)\n",
    "\n",
    "print(\"Saved YOLO dataset to:\", TARGET_DIR)\n",
    "yaml_path = \"/content/drive/MyDrive/vp-project-branch/FoodVision/data/foodseg_pp/data.yaml\"\n",
    "\n",
    "import yaml\n",
    "\n",
    "data = {\n",
    "    \"path\": \"/content/drive/MyDrive/vp-project-branch/FoodVision/data/foodseg_pp\",\n",
    "    \"train\": \"images/train\",\n",
    "    \"val\": \"images/val\",\n",
    "    \"test\": \"images/test\",\n",
    "    \"nc\": 104,\n",
    "    \"names\": [f\"class_{i}\" for i in range(104)]\n",
    "}\n",
    "\n",
    "with open(yaml_path, \"w\") as f:\n",
    "    yaml.dump(data, f, sort_keys=False)\n",
    "\n",
    "print(\"Wrote corrected data.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d62c5c8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load dataset from HuggingFace\n",
    "ds = load_dataset(\"ethz/food101\")\n",
    "# Save to Google Drive\n",
    "save_path = \"/content/drive/MyDrive/vp-project-branch/FoodVision/datasets/food101\"\n",
    "ds.save_to_disk(save_path)\n",
    "\n",
    "print(\"Saved to:\", save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d07aa9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "rf = Roboflow(api_key=\"KEY\")\n",
    "project = rf.workspace(\"foodx251\").project(\"foodx-251\")\n",
    "version = project.version(4)\n",
    "\n",
    "dataset = version.download(\n",
    "    model_format=\"folder\",  # classification dataset â†’ use \"folder\" format :contentReference[oaicite:0]{index=0}\n",
    "    location=\"/content/drive/MyDrive/vp-project-branch/FoodVision/datasets/foodx251\"\n",
    ")\n",
    "\n",
    "print(\"Downloaded to:\", dataset.location)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
